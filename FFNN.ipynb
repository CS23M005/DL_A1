{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CS23M005/DL_A1/blob/main/FFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "HpYTs31g_pIO",
        "outputId": "0297e063-7769-4a91-e288-8bf53cf0aa53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.5/263.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.42.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4SJx3D-MGUT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.datasets import mnist\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r-v6VwxL8Fv"
      },
      "outputs": [],
      "source": [
        "(X_train1, y_train1), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train1[0:20000]/255\n",
        "X_validation = X_train1[20001:25000]/255\n",
        "y_train = y_train1[0:20000]\n",
        "y_validation = y_train1[20001:25000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW4OfOhmp427"
      },
      "outputs": [],
      "source": [
        "samples_for_print = [];\n",
        "unique_labels = np.unique(y_train)\n",
        "u_l = np.copy(unique_labels)\n",
        "\n",
        "while(len(unique_labels)>0):\n",
        "  for i in range (0, len(y_train)):\n",
        "    if(y_train[i] == unique_labels[0]):\n",
        "      samples_for_print.append(X_train[i])\n",
        "      unique_labels = np.setdiff1d(unique_labels,unique_labels[0])\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYVnrvSf6jRI"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "rows = 2\n",
        "cols = int(len(samples_for_print)/rows)\n",
        "plt.figure(figsize = (4,2))\n",
        "for img in samples_for_print:\n",
        "    plt.subplot(rows, cols, i)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(u_l[i-1])\n",
        "    plt.tick_params(left = False, right = False , labelleft = False ,\n",
        "                labelbottom = False, bottom = False)\n",
        "    i = i+1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlez8ElJAxZJ"
      },
      "outputs": [],
      "source": [
        "from random import seed\n",
        "import random\n",
        "\n",
        "def init_random(n1, n2, init_mode, xav_std):\n",
        "  if init_mode == \"random\":\n",
        "    return [[np.random.normal(0,1) for i in range(n1)] for j in range(n2)]\n",
        "  elif init_mode == \"xavier\":\n",
        "    return [[np.random.normal(0,xav_std) for i in range(n1)] for j in range(n2)]\n",
        "\n",
        "def init_nn(n_inputs, n_layers, n_neurons, n_outputs, init_mode):\n",
        "  #print(\"in weight init\")\n",
        "  w = [0]*(n_layers+2)\n",
        "  biases = []\n",
        "  xavier_stddev = np.sqrt(2 / (n_inputs + n_outputs))\n",
        "  input_layer = init_random(n_inputs, n_neurons, init_mode, xavier_stddev)\n",
        "  w[1] = input_layer\n",
        "  biases.append([0])\n",
        "  biases.append(init_random(n_neurons, 1, init_mode, xavier_stddev)[0])\n",
        "  for i in range(2,n_layers+1):\n",
        "    hidden_layer = init_random(n_neurons, n_neurons, init_mode, xavier_stddev)\n",
        "    w[i] = hidden_layer\n",
        "    biases.append(init_random(n_neurons, 1, init_mode, xavier_stddev)[0])\n",
        "  output_layer = init_random(n_neurons, n_outputs, init_mode, xavier_stddev)\n",
        "  w[n_layers+1] = output_layer\n",
        "  biases.append(init_random(n_outputs, 1, init_mode, xavier_stddev)[0])\n",
        "  return w, biases\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1. / (1.+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return sigmoid(x) * (1-sigmoid(x))\n",
        "\n",
        "def Relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def Relu_derivative(x):\n",
        "  return 1*(x>0)\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "  return (1 - (np.tanh(x)**2))\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "def softmax_derivative(x):\n",
        "  return softmax(x) * (1-softmax(x))\n",
        "\n",
        "def oneHotEncode(y_actual, n_outputs):\n",
        "  Ydata = np.zeros(n_outputs)\n",
        "  Ydata[int(y_actual)] = 1\n",
        "  return Ydata\n",
        "\n"
      ],
      "metadata": {
        "id": "RzrSpYTD3HpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqZhCJsoR_pR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def forward_prop(w, b, sample, n_layers):\n",
        "  a = []\n",
        "  h = []\n",
        "  h.append(sample)\n",
        "  a.append([0])\n",
        "  for i in range(1, n_layers+1):\n",
        "    a.append(np.matmul(np.array(w[i]),np.array(h[i-1]))+b[i])\n",
        "    h.append(sigmoid(a[i]))\n",
        "  a.append(np.matmul(w[n_layers+1],h[n_layers])+b[n_layers+1])\n",
        "  y = softmax(a[n_layers+1])\n",
        "  return y, a, h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eEvDrKlLnBP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def backprop(y_hat, y_actual, a, h, w, b, activation_f, batch_size, loss, ud_lambda, n_outputs):\n",
        "\n",
        "    L = len(w)-1\n",
        "    gradient_a = [0]*(L+1)\n",
        "    gradient_w = [0]*(L+1)\n",
        "    gradient_b = [0]*(L+1)\n",
        "    gradient_h = [0]*(L+1)\n",
        "    y = oneHotEncode(y_actual, n_outputs)\n",
        "\n",
        "    if loss == 'crossentropy':\n",
        "      gradient_a[L] = y_hat-y\n",
        "    elif loss == 'mse':\n",
        "      gradient_a[L] = np.multiply(2 * (y_hat - y), np.multiply(y_hat, (1 - y_hat)))\n",
        "\n",
        "    for k in range(L,0,-1):\n",
        "      gradient_w[k] = (np.outer(gradient_a[k], h[k-1].transpose()))\n",
        "      gradient_b[k] = gradient_a[k]\n",
        "\n",
        "      if (k > 1):\n",
        "        if activation_f == 'sigmoid':\n",
        "          gradient_h[k-1] = np.matmul(np.array(w[k]).transpose(), np.array(gradient_a[k]))\n",
        "          gradient_a[k-1]  =np.array(gradient_h[k-1]) * np.array(sigmoid_derivative(a[k-1]))\n",
        "\n",
        "        elif activation_f == 'relu':\n",
        "          gradient_h[k-1] = np.matmul(np.array(w[k]).transpose(), np.array(gradient_a[k]))\n",
        "          gradient_a[k-1]  =np.array(gradient_h[k-1]) * np.array(Relu_derivative(a[k-1]))\n",
        "\n",
        "        elif activation_f == 'tanh':\n",
        "          gradient_h[k-1] = np.matmul(np.array(w[k]).transpose(), np.array(gradient_a[k]))\n",
        "          gradient_a[k-1]  =np.array(gradient_h[k-1]) * np.array(tanh_derivative(a[k-1]))\n",
        "\n",
        "    return gradient_w, gradient_b\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def sgd(n_inputs, n_layers, n_neurons, n_outputs, activation_f, batch_size, loss, ud_lambda, eta, init_mode, w, b, use_wandb):\n",
        "  print(\"in sgd\")\n",
        "  for i in range(3):\n",
        "    print(\"epoch\", i)\n",
        "    dw, db = 0,0\n",
        "    num_points_seen = 0\n",
        "    for x,y in zip(X_train, y_train):\n",
        "      sample = x.flatten()\n",
        "      y_hat, a, h = forward_prop(w, b, sample, n_layers)\n",
        "      temp_dw, temp_db = backprop(y_hat, y, a, h, w, b, activation_f, batch_size, loss, ud_lambda, n_outputs)\n",
        "      if(num_points_seen==0):\n",
        "        dw, db = temp_dw, temp_db\n",
        "        #print(\"dw, db init happened\", np.array(dw[1]).shape)\n",
        "      num_points_seen = num_points_seen + 1\n",
        "      for j in range(1, n_layers+2):\n",
        "          dw[j] = dw[j]+ np.array(temp_dw[j])\n",
        "          db[j] = db[j]+ np.array(temp_db[j])\n",
        "      #print(num_points_seen)\n",
        "      if (num_points_seen % batch_size) == 0:\n",
        "        #print(\"update rule start: \", num_points_seen)\n",
        "        for j in range(1, n_layers+2):\n",
        "          w[j] = (w[j]-eta*dw[j]) - eta*ud_lambda*np.array(w[j])\n",
        "          b[j] = b[j]-eta*db[j]\n",
        "        print(\"update rule end: \", num_points_seen)\n",
        "\n",
        "  return w,b,a,h\n",
        "\n"
      ],
      "metadata": {
        "id": "syzVDFw4A3j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(x_data,y_data, w, b, n_layers):\n",
        "  #print(\"in accuracy\")\n",
        "  count = 0\n",
        "  y_p = []\n",
        "  for x,y in zip(x_data,y_data):\n",
        "    sample = x.flatten()\n",
        "    y_hat, a_dum, h_dum = forward_prop(w, b, sample, n_layers)\n",
        "    y_pred = np.argmax(y_hat, axis=0)\n",
        "    y_p.append(y_pred)\n",
        "    if y_pred == y:\n",
        "      count += 1\n",
        "  accuracy = count/len(y_data)\n",
        "  print(count)\n",
        "  return accuracy, y_p\n",
        "\n"
      ],
      "metadata": {
        "id": "8cnF26HUhBkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\"name\": \"sgd-complete-sweep2\", \"method\": \"random\"}\n",
        "sweep_config[\"metric\"] = {\"name\": \"validation_acc\", \"goal\": \"maximize\"}\n",
        "parameters_dict = {\n",
        "                \"num_epochs\": {\"values\": [5, 10]}, \\\n",
        "                \"num_hidden_layers\": {\"values\": [3, 4]}, \\\n",
        "                \"size_hidden_layer\": {\"values\": [32, 64]}, \\\n",
        "                \"learning_rate\": {\"values\": [1e-3, 1e-4]}, \\\n",
        "                # \"optimizer\": {\"values\": [\"sgd\"]}, #,\"Momentum\",\"AdaGrad\",\"RMSProp\",\"Adam\",\"Nadam\"]}, \\\n",
        "                \"batch_size\": {\"values\": [1024, 4000]}, \\\n",
        "                \"weight_init\": {\"values\": [\"random\", \"xavier\"]} , \\\n",
        "                \"activation\": {\"values\": [\"sigmoid\", \"tanh\"]}, \\\n",
        "                \"loss\": {\"values\": [\"crossentropy\"]}, \\\n",
        "                \"reg_lambda\": {\"values\": [0.01, 0.001]}, \\\n",
        "                  }\n",
        "sweep_config[\"parameters\"] = parameters_dict"
      ],
      "metadata": {
        "id": "__Aujgt-46Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_nn(config = sweep_config):\n",
        "  with wandb.init(config = config):\n",
        "    config = wandb.config\n",
        "    wandb.run.name = \"e_{}_hl_{}_opt_{}_bs_{}_init_{}_ac_{}_loss_{}\".format(config.num_epochs,\\\n",
        "                                                                  config.num_hidden_layers,\\\n",
        "                                                                  config.size_hidden_layer,\\\n",
        "                                                                  config.learning_rate,\\\n",
        "                                                                  #config.optimizer,\\\n",
        "                                                                  config.batch_size,\\\n",
        "                                                                  config.weight_init,\\\n",
        "                                                                  config.activation,\\\n",
        "                                                                  config.loss,\\\n",
        "                                                                  config.reg_lambda)\n",
        "\n",
        "    seed(29)\n",
        "    n_inputs = 784\n",
        "    n_layers = config.size_hidden_layer\n",
        "    n_neurons = config.size_hidden_layer\n",
        "    n_outputs = 10\n",
        "    init_mode = config.weight_init\n",
        "    w,b = init_nn(n_inputs, n_layers, n_neurons, n_outputs, init_mode)\n",
        "    w_old = w.copy()\n",
        "    b_old = b.copy()\n",
        "\n",
        "    eta = config.learning_rate\n",
        "    activation_f = config.activation\n",
        "    batch_size = config.batch_size\n",
        "    loss = config.loss\n",
        "    ud_lambda = config.reg_lambda\n",
        "    #print(\"before sgd  call\")\n",
        "    w_n,b_n, a_n, h_n = sgd(n_inputs, n_layers, n_neurons, n_outputs, activation_f, batch_size, loss, ud_lambda, eta, init_mode, w, b, use_wandb=True)\n",
        "    #print(\"after sgd call\")\n",
        "    train_accuracy, yp = accuracy(X_train, y_train, w_n, b_n, n_layers)\n",
        "    validation_accuracy, yp = accuracy(X_validation, y_validation, w_n, b_n, n_layers)\n",
        "    #test_accuracy, ytp = accuracy(X_test, y_test, w_n, b_n, n_layers)\n",
        "\n",
        "\n",
        "    wandb.log({\"train_acc\": train_accuracy, \\\n",
        "               \"validation_acc\": validation_accuracy, \\\n",
        "                #\"test_acc\": test_accuracy, \\\n",
        "                })\n",
        "    print(\"accu: \", validation_accuracy)\n",
        "\n",
        "\n",
        "####################################################################\n",
        "sweep_id = wandb.sweep(sweep_config, project = \"Assignment1\")\n",
        "wandb.agent(sweep_id, function = train_nn, count=6)\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "6gH9a3VF5-wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_accuracy*100)\n",
        "# print(test_accuracy*100)"
      ],
      "metadata": {
        "id": "h3WCeFCWoge1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(w_old[n_layers][1], 'o')\n",
        "# plt.plot(w_n[n_layers][1], 'o')\n",
        "# # plt.show()"
      ],
      "metadata": {
        "id": "lYAH1uhNII5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(b_old[1], 'o')\n",
        "# plt.plot(b_n[1], 'o')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "x5EhgJBhWila"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample = X_train[0].flatten()\n",
        "# y_hat, a, h = forward_prop(w, b, sample, n_layers)\n",
        "# dw, db = backprop(y_hat, y_train[0], a, h, w, b, activation_f, batch_size, loss, ud_lambda, n_outputs)"
      ],
      "metadata": {
        "id": "74nEFu_RXPHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(0,n_layers+2):\n",
        "#   print(np.array(b[i]).shape)"
      ],
      "metadata": {
        "id": "C6mZSatNIeNx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw28uyd6PkjObRSpDd5jG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}